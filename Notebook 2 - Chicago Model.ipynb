{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuel Library for Data\n",
    "\n",
    "Notebook #1 explored the data that we were dealing with. This notebook utilizes the [Fuel library](https://github.com/mila-udem/fuel), which wraps data for machine learning pipelines, and the [lfw_fuel library](https://github.com/dribnet/lfw_fuel), which extends the Fuel library to the LFW dataset.\n",
    "\n",
    "This enables us to load image data and convert it into X and Y training/testing vectors in one call, like this:\n",
    "\n",
    "```\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"funneled\")\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"deepfunneled\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize \n",
    "\n",
    "from lfw_fuel import lfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 12\n",
    "feature_width = 32\n",
    "feature_height = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cropImage(im):\n",
    "    im2 = np.dstack(im).astype(np.uint8)\n",
    "    # return centered 128x128 from original 250x250 (40% of area)\n",
    "    newim = im2[61:189, 61:189]\n",
    "    sized1 = imresize(newim[:,:,0:3], (feature_width, feature_height), interp=\"bicubic\", mode=\"RGB\")\n",
    "    sized2 = imresize(newim[:,:,3:6], (feature_width, feature_height), interp=\"bicubic\", mode=\"RGB\")\n",
    "    return np.asarray([sized1[:,:,0], sized1[:,:,1], sized1[:,:,2], sized2[:,:,0], sized2[:,:,1], sized2[:,:,2]])\n",
    "\n",
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"deepfunneled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crop features\n",
    "X_train = np.asarray(list(map(cropImage, X_train)))\n",
    "X_test = np.asarray(list(map(cropImage, X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 train samples, 6 channels, 32x32\n",
      "1000  test samples, 6 channels, 32x32\n"
     ]
    }
   ],
   "source": [
    "# print shape of data\n",
    "print(\"{1} train samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_train.shape[1] == 1 else \"s\", *X_train.shape))\n",
    "print(\"{1}  test samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_test.shape[1] == 1 else \"s\", *X_test.shape))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In general, it is a good idea to use normalized data.\n",
    "# We compute these for now, but don't use them below. Save for later.\n",
    "X_train_float = X_train.astype('float32')\n",
    "X_train_float /= 255\n",
    "\n",
    "X_test_float = X_test.astype('float32')\n",
    "X_test_float /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Now that we've used the fuel library to load our data, we're ready to train our first neural network. We will use a convolutional neural network, useful for image recognition and classification tasks.\n",
    "\n",
    "(Useful links on [convolutional neural networks](http://machinelearningmastery.com/crash-course-convolutional-neural-networks/) and [object recognition](http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/) from Dr. Jason Brownlee, very helpful in understanding these concepts. [Book chaper](http://neuralnetworksanddeeplearning.com/chap6.html) from Michael Nielsen also useful.)\n",
    "\n",
    "Convolutional neural networks use three types of layers:\n",
    "* Convolutional layers\n",
    "* Pooling layers\n",
    "* Fully connected layers\n",
    "\n",
    "Convolutional layers are comprised of filters and feature maps. \n",
    "* Filters are the neurons of the layer, which have inputs, weights, and outputs. Input size is a fixed patch. For input convolutional layers, these patches are pixels striaght from the image. Deeper in the neural network, the patches are the outputs from prior layers.\n",
    "* Feature maps are how outputs from one layer are connected to inputs at the next layer. \n",
    "* Padding is necessitated by the fact that one layer's output sie may not be cleanly divisible by the filter patch at the next layer. Zero padding can be used to keep the neural net from reading off the edge of the image.\n",
    "\n",
    "Pooling layers down-sample a given layer.\n",
    "* Pooling acts as a compression or dimensionality reduction, condensing the features learned in prior layers to the most important ones. Their input size is often much smaller than the convolutional layer they are connected to. \n",
    "* These create their own feature maps (how outputs from one layer are connected to inputs at the next layer), often using an average or maximum function.\n",
    "\n",
    "Fully connected layers are used to combine the various extracted features.\n",
    "* Fully connected layers create a non-linear combination of all incoming features.\n",
    "* Activation functions at the connected layer is often a softmax or non-linear function. \n",
    "* These can be thought of as predicting the probability of a particular class or classification.\n",
    "\n",
    "The general architecture of a convolutional neural network is:\n",
    "* Convolution\n",
    "* Convolution\n",
    "* Pool\n",
    "* Dropout\n",
    "* Flatten\n",
    "* Dense\n",
    "* Dropout\n",
    "* Dense\n",
    "\n",
    "This can take other forms, like:\n",
    "* Convolution\n",
    "* Dropout\n",
    "* Convolution\n",
    "* Pool\n",
    "* Flatten\n",
    "* Dense/Fully connected\n",
    "* Dropout\n",
    "* Dense/Fully connected (n_classes)\n",
    "\n",
    "Optionally, to add more convolution layers,\n",
    "* Convolution (32 feature maps)\n",
    "* Dropout\n",
    "* Convolution (32 feature maps)\n",
    "* Pool\n",
    "* Convolution (64 feature maps)\n",
    "* Dropout\n",
    "* Convolution (64 feature maps)\n",
    "* Pool\n",
    "* Convolution (128 feature maps)\n",
    "* Dropout\n",
    "* Convolution (128 feature maps)\n",
    "* Pool\n",
    "* Flatten\n",
    "* Dropout\n",
    "* Dense/Fully connected (1024)\n",
    "* Dropout\n",
    "* Dense/Fully connected (512)\n",
    "* Dropout\n",
    "* Dense/Fully connected (n_classes)\n",
    "\n",
    "In Keras, it takes a little bit of effort to understand how to get all of the layers to line up. The comments in the neural network constructed below should explain what's happening at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 6, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_maps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-407e9f710c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#1 Convulution, Activation, Pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m chicago.add( Conv2D(feature_maps, \n\u001b[0m\u001b[1;32m     10\u001b[0m                     \u001b[0mfeature_maps_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_maps' is not defined"
     ]
    }
   ],
   "source": [
    "chicago = Sequential()\n",
    "\n",
    "# Convolutional input layer,\n",
    "# specify number of feature maps,\n",
    "# size of feature maps,\n",
    "# image sizes are (6, 32, 32) - 6 color channels, 32 x 32 pixels\n",
    "\n",
    "#1 Convulution, Activation, Pooling\n",
    "chicago.add( Conv2D(32, (3, 3), input_shape=(6, 32, 32),\n",
    "                    padding='valid') )\n",
    "\n",
    "chicago.add( Activation('relu') )\n",
    "\n",
    "chicago.add( MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)) )\n",
    "\n",
    "\n",
    "#2 Convulution, Activation, Pooling\n",
    "chicago.add( Conv2D(32, (3, 3), input_shape=(6, 32, 32),\n",
    "                    padding='valid') )\n",
    "\n",
    "chicago.add( Activation('relu') )\n",
    "\n",
    "chicago.add( MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)) )\n",
    "\n",
    "\n",
    "#1 FC/Dense, Activation\n",
    "chicago.add( Flatten() )\n",
    "\n",
    "chicago.add( Dense(128, activation='relu') )\n",
    "\n",
    "chicago.add( Activation('relu') )\n",
    "\n",
    "\n",
    "#2 FC/Dense, Activation\n",
    "chicago.add( Flatten() ) \n",
    "\n",
    "chicago.add( Dense(2, activation='softmax') )\n",
    "\n",
    "chicago.add( Activation('relu') )\n",
    "\n",
    "\n",
    "print(chicago.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model:\n",
    "# A logarithmic loss function is used with \n",
    "# stochastic gradient descent optimization algorithm\n",
    "# configured with a large momentum and weight decay \n",
    "# starting with a learning rate of 0.01.\n",
    "epochs = 12\n",
    "lrate = 0.1\n",
    "decay = lrate/epochs\n",
    "batch_size = 32\n",
    "\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "chicago.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2200 samples, validate on 1000 samples\n",
      "Epoch 1/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6975 - binary_accuracy: 0.4945 - val_loss: 0.7126 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.7035 - binary_accuracy: 0.4814 - val_loss: 0.6929 - val_binary_accuracy: 0.5140\n",
      "Epoch 3/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6931 - binary_accuracy: 0.5191 - val_loss: 0.6933 - val_binary_accuracy: 0.5090\n",
      "Epoch 4/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6938 - binary_accuracy: 0.4995 - val_loss: 0.6944 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6915 - binary_accuracy: 0.5045 - val_loss: 0.6929 - val_binary_accuracy: 0.4990\n",
      "Epoch 6/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6900 - binary_accuracy: 0.5232 - val_loss: 0.6940 - val_binary_accuracy: 0.4970\n",
      "Epoch 7/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6879 - binary_accuracy: 0.5327 - val_loss: 0.6951 - val_binary_accuracy: 0.5070\n",
      "Epoch 8/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6878 - binary_accuracy: 0.5109 - val_loss: 0.6950 - val_binary_accuracy: 0.4900\n",
      "Epoch 9/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6838 - binary_accuracy: 0.5386 - val_loss: 0.6945 - val_binary_accuracy: 0.4950\n",
      "Epoch 10/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6827 - binary_accuracy: 0.5218 - val_loss: 0.6973 - val_binary_accuracy: 0.4870\n",
      "Epoch 11/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6813 - binary_accuracy: 0.5364 - val_loss: 0.6978 - val_binary_accuracy: 0.5020\n",
      "Epoch 12/12\n",
      "2200/2200 [==============================] - 0s - loss: 0.6794 - binary_accuracy: 0.5382 - val_loss: 0.6979 - val_binary_accuracy: 0.5030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b080dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicago.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Model A (12 epochs):\n",
      "Test accuracy: 50.300000%\n"
     ]
    }
   ],
   "source": [
    "# lower-case y_test is not encoded, CAPITAL Y_test is hot-encoded\n",
    "# use CAPITAL-Y_test!!\n",
    "score = chicago.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Chicago Model (12 epochs):\")\n",
    "print('Test accuracy: {0:%}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What A Terrible Model\n",
    "\n",
    "It is a bit of a disappointment to get such an awful result from our neural network, but remember, this was just our first pass. Some other things we can work on:\n",
    "* Use normalized data\n",
    "* Add additional convolutional layers to the neural network\n",
    "* Train for more epochs\n",
    "* Use larger neural network layers (more neurons per network)\n",
    "\n",
    "Let's run Chicago1 Model, which is the same as Chicago Model, but for 120 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 4, 30, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 28, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               57472     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 76,226\n",
      "Trainable params: 76,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "chicago1 = Sequential()\n",
    "\n",
    "# Convolutional input layer,\n",
    "# specify number of feature maps,\n",
    "# size of feature maps,\n",
    "# image sizes are (6, 32, 32) - 6 color channels, 32 x 32 pixels\n",
    "\n",
    "#1 Convulution, Activation, Pooling\n",
    "chicago1.add( Conv2D(32, (3, 3), input_shape=(6, 32, 32),\n",
    "                    padding='valid') )\n",
    "\n",
    "chicago1.add( Activation('relu') )\n",
    "\n",
    "chicago1.add( MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)) )\n",
    "\n",
    "\n",
    "#2 Convulution, Activation, Pooling\n",
    "chicago1.add( Conv2D(32, (3, 3), input_shape=(6, 32, 32),\n",
    "                    padding='valid') )\n",
    "\n",
    "chicago1.add( Activation('relu') )\n",
    "\n",
    "chicago1.add( MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)) )\n",
    "\n",
    "\n",
    "#1 FC/Dense, Activation\n",
    "chicago1.add( Flatten() )\n",
    "\n",
    "chicago1.add( Dense(128, activation='relu') )\n",
    "\n",
    "chicago1.add( Activation('relu') )\n",
    "\n",
    "\n",
    "#2 FC/Dense, Activation\n",
    "chicago1.add( Flatten() ) \n",
    "\n",
    "chicago1.add( Dense(2, activation='softmax') )\n",
    "\n",
    "chicago1.add( Activation('relu') )\n",
    "\n",
    "\n",
    "# Compile model:\n",
    "# A logarithmic loss function is used with \n",
    "# stochastic gradient descent optimization algorithm\n",
    "# configured with a large momentum and weight decay \n",
    "# starting with a learning rate of 0.01.\n",
    "epochs = 120\n",
    "lrate = 0.1\n",
    "decay = lrate/epochs\n",
    "batch_size = 32\n",
    "\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "chicago1.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['binary_accuracy'])\n",
    "\n",
    "print(chicago1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2200 samples, validate on 1000 samples\n",
      "Epoch 1/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4128 - binary_accuracy: 0.7077 - val_loss: 1.7389 - val_binary_accuracy: 0.4810\n",
      "Epoch 2/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4010 - binary_accuracy: 0.7191 - val_loss: 1.7357 - val_binary_accuracy: 0.4870\n",
      "Epoch 3/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4053 - binary_accuracy: 0.7114 - val_loss: 1.7116 - val_binary_accuracy: 0.4830\n",
      "Epoch 4/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4153 - binary_accuracy: 0.7091 - val_loss: 1.6911 - val_binary_accuracy: 0.4960\n",
      "Epoch 5/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4048 - binary_accuracy: 0.7259 - val_loss: 1.7461 - val_binary_accuracy: 0.5060\n",
      "Epoch 6/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4131 - binary_accuracy: 0.7200 - val_loss: 1.6336 - val_binary_accuracy: 0.4960\n",
      "Epoch 7/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4057 - binary_accuracy: 0.7236 - val_loss: 1.7051 - val_binary_accuracy: 0.4940\n",
      "Epoch 8/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4011 - binary_accuracy: 0.7318 - val_loss: 1.7323 - val_binary_accuracy: 0.4970\n",
      "Epoch 9/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4020 - binary_accuracy: 0.7277 - val_loss: 1.6954 - val_binary_accuracy: 0.4910\n",
      "Epoch 10/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3998 - binary_accuracy: 0.7268 - val_loss: 1.6920 - val_binary_accuracy: 0.4830\n",
      "Epoch 11/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4015 - binary_accuracy: 0.7114 - val_loss: 1.7318 - val_binary_accuracy: 0.4930\n",
      "Epoch 12/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4072 - binary_accuracy: 0.7136 - val_loss: 1.6969 - val_binary_accuracy: 0.4930\n",
      "Epoch 13/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3975 - binary_accuracy: 0.7264 - val_loss: 1.7277 - val_binary_accuracy: 0.4880\n",
      "Epoch 14/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3958 - binary_accuracy: 0.7277 - val_loss: 1.7542 - val_binary_accuracy: 0.4910\n",
      "Epoch 15/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3943 - binary_accuracy: 0.7323 - val_loss: 1.8314 - val_binary_accuracy: 0.4850\n",
      "Epoch 16/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3985 - binary_accuracy: 0.7182 - val_loss: 1.8048 - val_binary_accuracy: 0.4890\n",
      "Epoch 17/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3939 - binary_accuracy: 0.7205 - val_loss: 1.8177 - val_binary_accuracy: 0.4840\n",
      "Epoch 18/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4003 - binary_accuracy: 0.7245 - val_loss: 1.7723 - val_binary_accuracy: 0.4810\n",
      "Epoch 19/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3943 - binary_accuracy: 0.7291 - val_loss: 1.8365 - val_binary_accuracy: 0.4770\n",
      "Epoch 20/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3995 - binary_accuracy: 0.7164 - val_loss: 1.8457 - val_binary_accuracy: 0.4770\n",
      "Epoch 21/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4000 - binary_accuracy: 0.7232 - val_loss: 1.8389 - val_binary_accuracy: 0.4820\n",
      "Epoch 22/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3975 - binary_accuracy: 0.7259 - val_loss: 1.7377 - val_binary_accuracy: 0.4930\n",
      "Epoch 23/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4029 - binary_accuracy: 0.7259 - val_loss: 1.6865 - val_binary_accuracy: 0.4940\n",
      "Epoch 24/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4003 - binary_accuracy: 0.7159 - val_loss: 1.7770 - val_binary_accuracy: 0.4810\n",
      "Epoch 25/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3899 - binary_accuracy: 0.7327 - val_loss: 1.8759 - val_binary_accuracy: 0.4900\n",
      "Epoch 26/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3992 - binary_accuracy: 0.7223 - val_loss: 1.7861 - val_binary_accuracy: 0.4900\n",
      "Epoch 27/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3994 - binary_accuracy: 0.7109 - val_loss: 1.7686 - val_binary_accuracy: 0.4860\n",
      "Epoch 28/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3955 - binary_accuracy: 0.7268 - val_loss: 1.7957 - val_binary_accuracy: 0.4870\n",
      "Epoch 29/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.4039 - binary_accuracy: 0.7232 - val_loss: 1.6756 - val_binary_accuracy: 0.4870\n",
      "Epoch 30/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3980 - binary_accuracy: 0.7145 - val_loss: 1.8125 - val_binary_accuracy: 0.4820\n",
      "Epoch 31/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3944 - binary_accuracy: 0.7205 - val_loss: 1.8274 - val_binary_accuracy: 0.4810\n",
      "Epoch 32/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3948 - binary_accuracy: 0.7200 - val_loss: 1.8998 - val_binary_accuracy: 0.4910\n",
      "Epoch 33/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3944 - binary_accuracy: 0.7232 - val_loss: 1.8650 - val_binary_accuracy: 0.4950\n",
      "Epoch 34/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3941 - binary_accuracy: 0.7227 - val_loss: 1.8722 - val_binary_accuracy: 0.4780\n",
      "Epoch 35/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3942 - binary_accuracy: 0.7182 - val_loss: 1.8685 - val_binary_accuracy: 0.4790\n",
      "Epoch 36/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3891 - binary_accuracy: 0.7155 - val_loss: 1.9328 - val_binary_accuracy: 0.4790\n",
      "Epoch 37/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3923 - binary_accuracy: 0.7209 - val_loss: 1.9071 - val_binary_accuracy: 0.4840\n",
      "Epoch 38/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3917 - binary_accuracy: 0.7118 - val_loss: 1.9173 - val_binary_accuracy: 0.4820\n",
      "Epoch 39/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3922 - binary_accuracy: 0.7268 - val_loss: 1.8830 - val_binary_accuracy: 0.4820\n",
      "Epoch 40/40\n",
      "2200/2200 [==============================] - 0s - loss: 0.3917 - binary_accuracy: 0.7114 - val_loss: 1.8923 - val_binary_accuracy: 0.4850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11faaf0f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicago1.fit(X_train, Y_train, batch_size=batch_size, epochs=40, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Model B (120 epochs):\n",
      "Test accuracy: 48.500000%\n"
     ]
    }
   ],
   "source": [
    "# lower-case y_test is not encoded, CAPITAL Y_test is hot-encoded\n",
    "# use CAPITAL-Y_test!!\n",
    "score = chicago1.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Chicago1 Model (120 epochs):\")\n",
    "print('Test accuracy: {0:%}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Yikes! That is still a pretty bad result. In the next notebook we'll work on building out the neural network and try to improve on these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
