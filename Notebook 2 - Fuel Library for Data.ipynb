{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuel Library for Data\n",
    "\n",
    "Notebook #1 explored the data that we were dealing with. This notebook utilizes the [Fuel library](https://github.com/mila-udem/fuel), which wraps data for machine learning pipelines, and the [lfw_fuel library](https://github.com/dribnet/lfw_fuel), which extends the Fuel library to the LFW dataset.\n",
    "\n",
    "This enables us to load image data and convert it into X and Y training/testing vectors in one call, like this:\n",
    "\n",
    "```\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"funneled\")\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"deepfunneled\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, MaxPooling3D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfw_fuel import lfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 1\n",
    "nb_epoch = 12\n",
    "feature_width = 32\n",
    "feature_height = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(im):\n",
    "    im2 = np.dstack(im).astype(np.uint8)\n",
    "    # return centered 128x128 from original 250x250 (40% of area)\n",
    "    newim = im2[61:189, 61:189]\n",
    "    sized1 = imresize(newim[:,:,0:3], (feature_width, feature_height), interp=\"bicubic\", mode=\"RGB\")\n",
    "    sized2 = imresize(newim[:,:,3:6], (feature_width, feature_height), interp=\"bicubic\", mode=\"RGB\")\n",
    "    return np.asarray([sized1[:,:,0], sized1[:,:,1], sized1[:,:,2], sized2[:,:,0], sized2[:,:,1], sized2[:,:,2]])\n",
    "\n",
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"deepfunneled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop features\n",
    "X_train = np.asarray(list(map(cropImage, X_train)))\n",
    "X_test = np.asarray(list(map(cropImage, X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 train samples, 6 channels, 32x32\n",
      "1000  test samples, 6 channels, 32x32\n"
     ]
    }
   ],
   "source": [
    "# print shape of data\n",
    "print(\"{1} train samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_train.shape[1] == 1 else \"s\", *X_train.shape))\n",
    "print(\"{1}  test samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_test.shape[1] == 1 else \"s\", *X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "# (only use to_categorical if nb_classes > 1)\n",
    "Y_train = y_train #np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test  = y_test  #np_utils.to_categorical(y_test, nb_classes)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 train predictions, 1-dimension\n",
      "1000  test predictions, 1-dimension\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} train predictions, {1}-dimension\".format(*Y_train.shape))\n",
    "print(\"{0}  test predictions, {1}-dimension\".format(*Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general, it is a good idea to use normalized data.\n",
    "# We compute these for now, but don't use them below. Save for later.\n",
    "X_train_float = X_train.astype('float32')\n",
    "X_train_float /= 255\n",
    "\n",
    "X_test_float = X_test.astype('float32')\n",
    "X_test_float /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Now that we've used the fuel library to load our data, we're ready to train our first neural network. We will use a convolutional neural network, useful for image recognition and classification tasks.\n",
    "\n",
    "(Useful links on [convolutional neural networks](http://machinelearningmastery.com/crash-course-convolutional-neural-networks/) and [object recognition](http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/) from Dr. Jason Brownlee, very helpful in understanding these concepts. [Book chaper](http://neuralnetworksanddeeplearning.com/chap6.html) from Michael Nielsen also useful.)\n",
    "\n",
    "Convolutional neural networks use three types of layers:\n",
    "* Convolutional layers\n",
    "* Pooling layers\n",
    "* Fully connected layers\n",
    "\n",
    "Convolutional layers are comprised of filters and feature maps. \n",
    "* Filters are the neurons of the layer, which have inputs, weights, and outputs. Input size is a fixed patch. For input convolutional layers, these patches are pixels striaght from the image. Deeper in the neural network, the patches are the outputs from prior layers.\n",
    "* Feature maps are how outputs from one layer are connected to inputs at the next layer. \n",
    "* Padding is necessitated by the fact that one layer's output sie may not be cleanly divisible by the filter patch at the next layer. Zero padding can be used to keep the neural net from reading off the edge of the image.\n",
    "\n",
    "Pooling layers down-sample a given layer.\n",
    "* Pooling acts as a compression or dimensionality reduction, condensing the features learned in prior layers to the most important ones. Their input size is often much smaller than the convolutional layer they are connected to. \n",
    "* These create their own feature maps (how outputs from one layer are connected to inputs at the next layer), often using an average or maximum function.\n",
    "\n",
    "Fully connected layers are used to combine the various extracted features.\n",
    "* Fully connected layers create a non-linear combination of all incoming features.\n",
    "* Activation functions at the connected layer is often a softmax or non-linear function. \n",
    "* These can be thought of as predicting the probability of a particular class or classification.\n",
    "\n",
    "The general architecture of a convolutional neural network is:\n",
    "* Convolution\n",
    "* Convolution\n",
    "* Pool\n",
    "* Dropout\n",
    "* Flatten\n",
    "* Dense\n",
    "* Dropout\n",
    "* Dense\n",
    "\n",
    "This can take other forms, like:\n",
    "* Convolution\n",
    "* Dropout\n",
    "* Convolution\n",
    "* Pool\n",
    "* Flatten\n",
    "* Dense/Fully connected\n",
    "* Dropout\n",
    "* Dense/Fully connected (n_classes)\n",
    "\n",
    "Optionally, to add more convolution layers,\n",
    "* Convolution (32 feature maps)\n",
    "* Dropout\n",
    "* Convolution (32 feature maps)\n",
    "* Pool\n",
    "* Convolution (64 feature maps)\n",
    "* Dropout\n",
    "* Convolution (64 feature maps)\n",
    "* Pool\n",
    "* Convolution (128 feature maps)\n",
    "* Dropout\n",
    "* Convolution (128 feature maps)\n",
    "* Pool\n",
    "* Flatten\n",
    "* Dropout\n",
    "* Dense/Fully connected (1024)\n",
    "* Dropout\n",
    "* Dense/Fully connected (512)\n",
    "* Dropout\n",
    "* Dense/Fully connected (n_classes)\n",
    "\n",
    "In Keras, it takes a little bit of effort to understand how to get all of the layers to line up. The comments in the neural network constructed below should explain what's happening at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 6, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_float))\n",
    "#\n",
    "# 2200 = number of training images\n",
    "# 6 = 3 color channels x 2 images\n",
    "# 32 x 32 = image w x h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "=================================================================\n",
      "Total params: 9,248\n",
      "Trainable params: 9,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelA = Sequential()\n",
    "\n",
    "# Convolutional input layer:\n",
    "# - 32 feature maps\n",
    "# - each feature map has size of 3 x 3\n",
    "# - (not sure how that math works out)\n",
    "# - \"weight constraint of max norm set to 3\" <-- ???\n",
    "# - Image size: (6, 32, 32)\n",
    "# - 2 images, 3 channels each, 32 x 32 pixels\n",
    "modelA.add(Conv2D(32, \n",
    "                  (3, 3), \n",
    "                  input_shape=(6, 32, 32),\n",
    "                  padding='same', \n",
    "                  activation='relu'))\n",
    "\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "=================================================================\n",
      "Total params: 18,496\n",
      "Trainable params: 18,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second convolutional layer, \n",
    "# 32 feature maps with a size of 3×3, \n",
    "# a rectifier activation function \n",
    "# and a weight constraint of max norm set to 3.\n",
    "modelA.add(Conv2D(32, (3, 3), \n",
    "                  input_shape=(6, 32, 32),\n",
    "                  padding='same', \n",
    "                  activation='relu'))\n",
    "\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 8)           0         \n",
      "=================================================================\n",
      "Total params: 18,496\n",
      "Trainable params: 18,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Max Pool layer with size 2×2.\n",
    "modelA.add(MaxPooling2D(pool_size=(4, 4),\n",
    "                       data_format='channels_first'))\n",
    "\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 8, 8)           0         \n",
      "=================================================================\n",
      "Total params: 18,496\n",
      "Trainable params: 18,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dropout set to 20%\n",
    "modelA.add(Dropout(0.2))\n",
    "\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "=================================================================\n",
      "Total params: 18,496\n",
      "Trainable params: 18,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Flatten layer.\n",
    "modelA.add(Flatten())\n",
    "\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               49280     \n",
      "=================================================================\n",
      "Total params: 67,776\n",
      "Trainable params: 67,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Fully connected layer with 128 units and a rectifier activation function.\n",
    "modelA.add(Dense(128, activation='relu'))\n",
    "\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 67,776\n",
      "Trainable params: 67,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dropout set to 50%.\n",
    "modelA.add(Dropout(0.5))\n",
    "\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 67,905\n",
      "Trainable params: 67,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fully connected output layer with 2 units (Y/N) \n",
    "# and a softmax activation function.\n",
    "modelA.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(modelA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All at once:\n",
    "modelA = Sequential()\n",
    "\n",
    "modelA.add(Conv2D(32, \n",
    "                  (3, 3), \n",
    "                  input_shape=(6, 32, 32),\n",
    "                  padding='same', \n",
    "                  activation='relu'))\n",
    "\n",
    "modelA.add(Conv2D(32, (3, 3), \n",
    "                  input_shape=(6, 32, 32),\n",
    "                  padding='same', \n",
    "                  activation='relu'))\n",
    "\n",
    "modelA.add(MaxPooling2D(pool_size=(4, 4),\n",
    "                       data_format='channels_first'))\n",
    "\n",
    "modelA.add(Dropout(0.2))\n",
    "modelA.add(Flatten())\n",
    "modelA.add(Dense(128, activation='relu'))\n",
    "modelA.add(Dropout(0.5))\n",
    "modelA.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model:\n",
    "# A logarithmic loss function is used with \n",
    "# stochastic gradient descent optimization algorithm\n",
    "# configured with a large momentum and weight decay \n",
    "# starting with a learning rate of 0.01.\n",
    "epochs = 12\n",
    "lrate = 0.1\n",
    "decay = lrate/epochs\n",
    "batch_size = 128\n",
    "\n",
    "modelA.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6, 32, 32)\n",
      "(1000, 1)\n",
      "(2200, 6, 32, 32)\n",
      "(2200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_test))\n",
    "print(np.shape(Y_test))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were trying to predict \"Are these faces the same?\", the output vectors (Y_test and Y_train) should be vectors. That is, they should have shape `(2200, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2200 samples, validate on 1000 samples\n",
      "Epoch 1/12\n",
      "2200/2200 [==============================] - 4s - loss: 0.6939 - binary_accuracy: 0.5136 - val_loss: 0.6955 - val_binary_accuracy: 0.5010\n",
      "Epoch 2/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6895 - binary_accuracy: 0.5282 - val_loss: 0.6964 - val_binary_accuracy: 0.4940\n",
      "Epoch 3/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6876 - binary_accuracy: 0.5291 - val_loss: 0.6968 - val_binary_accuracy: 0.4920\n",
      "Epoch 4/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6845 - binary_accuracy: 0.5418 - val_loss: 0.6975 - val_binary_accuracy: 0.4820\n",
      "Epoch 5/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6824 - binary_accuracy: 0.5555 - val_loss: 0.6984 - val_binary_accuracy: 0.4770\n",
      "Epoch 6/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6752 - binary_accuracy: 0.5491 - val_loss: 0.6990 - val_binary_accuracy: 0.4960\n",
      "Epoch 7/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6686 - binary_accuracy: 0.5627 - val_loss: 0.6982 - val_binary_accuracy: 0.4870\n",
      "Epoch 8/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6623 - binary_accuracy: 0.5736 - val_loss: 0.7008 - val_binary_accuracy: 0.4800\n",
      "Epoch 9/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6541 - binary_accuracy: 0.5745 - val_loss: 0.7090 - val_binary_accuracy: 0.4790\n",
      "Epoch 10/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6448 - binary_accuracy: 0.6036 - val_loss: 0.7146 - val_binary_accuracy: 0.4810\n",
      "Epoch 11/12\n",
      "2200/2200 [==============================] - 4s - loss: 0.6358 - binary_accuracy: 0.6086 - val_loss: 0.7082 - val_binary_accuracy: 0.4850\n",
      "Epoch 12/12\n",
      "2200/2200 [==============================] - 3s - loss: 0.6188 - binary_accuracy: 0.6250 - val_loss: 0.7132 - val_binary_accuracy: 0.4960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11dfc2358>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA.fit(X_train, Y_train, \n",
    "           batch_size=batch_size, \n",
    "           epochs=epochs, \n",
    "           verbose=1, \n",
    "           validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Model A (12 epochs):\n",
      "Test accuracy: 49.600000%\n"
     ]
    }
   ],
   "source": [
    "score = modelA.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Model A (12 epochs):\")\n",
    "print('Test accuracy: {0:%}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What A Terrible Model\n",
    "\n",
    "It is a bit of a disappointment to get such an awful result from our neural network, but remember, this was just our first pass. Some other things we can work on:\n",
    "* Use normalized data\n",
    "* Add additional convolutional layers to the neural network\n",
    "* Train for more epochs\n",
    "* Use larger neural network layers (more neurons per network)\n",
    "\n",
    "Let's run Model B, which implements the following changes:\n",
    "* Less pooling\n",
    "* Normalized data\n",
    "* 40 epochs instead of 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 16, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6, 16, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 215,361\n",
      "Trainable params: 215,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "modelB = Sequential()\n",
    "\n",
    "# Convolutional input layer\n",
    "modelB.add(Conv2D(32, \n",
    "                  (3, 3), \n",
    "                  input_shape=(6, 32, 32),\n",
    "                  padding='same', \n",
    "                  activation='relu'))\n",
    "\n",
    "\n",
    "# Convolutional layer\n",
    "modelB.add(Conv2D(32, (3, 3), \n",
    "                  input_shape=(6, 32, 32),\n",
    "                  padding='same', \n",
    "                  activation='relu'))\n",
    "\n",
    "# Max Pool layer with size 2×2.\n",
    "modelB.add(MaxPooling2D(pool_size=(2,2),\n",
    "                       data_format='channels_first'))\n",
    "\n",
    "\n",
    "# Dropout set to 20%\n",
    "modelB.add(Dropout(0.2))\n",
    "\n",
    "# Flatten layer.\n",
    "modelB.add(Flatten())\n",
    "\n",
    "# Fully connected layer with 128 units and a rectifier activation function.\n",
    "modelB.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Dropout set to 50%.\n",
    "modelB.add(Dropout(0.5))\n",
    "\n",
    "# Fully connected output layer with 2 units (Y/N) \n",
    "# and a softmax activation function.\n",
    "modelB.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Compile model:\n",
    "# A logarithmic loss function is used with \n",
    "# stochastic gradient descent optimization algorithm\n",
    "# configured with a large momentum and weight decay \n",
    "# starting with a learning rate of... oh, let's say 0.01\n",
    "epochs = 120\n",
    "lrate = 0.4\n",
    "decay = lrate/epochs\n",
    "batch_size = 32\n",
    "\n",
    "#sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "modelB.compile(loss='binary_crossentropy', \n",
    "               optimizer='rmsprop', \n",
    "               metrics=['binary_accuracy'])\n",
    "\n",
    "print(modelB.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2200 samples, validate on 1000 samples\n",
      "Epoch 1/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6939 - binary_accuracy: 0.4823 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6934 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6934 - binary_accuracy: 0.4955 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6932 - binary_accuracy: 0.4900 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6933 - binary_accuracy: 0.4864 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6932 - binary_accuracy: 0.5100 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6931 - binary_accuracy: 0.4977 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6934 - binary_accuracy: 0.4882 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6934 - binary_accuracy: 0.4800 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6932 - binary_accuracy: 0.4959 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6933 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6933 - binary_accuracy: 0.4918 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/40\n",
      "2200/2200 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5014 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6933 - binary_accuracy: 0.5068 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6932 - binary_accuracy: 0.5023 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6934 - binary_accuracy: 0.4832 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6932 - binary_accuracy: 0.4977 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6932 - binary_accuracy: 0.4809 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5145 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6932 - binary_accuracy: 0.4973 - val_loss: 0.6931 - val_binary_accuracy: 0.50000.49\n",
      "Epoch 21/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6934 - binary_accuracy: 0.4805 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6931 - binary_accuracy: 0.5086 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6937 - binary_accuracy: 0.4695 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6933 - binary_accuracy: 0.4841 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6933 - binary_accuracy: 0.4964 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/40\n",
      "2200/2200 [==============================] - 5s - loss: 0.6932 - binary_accuracy: 0.4936 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6933 - binary_accuracy: 0.4859 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6932 - binary_accuracy: 0.4832 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6933 - binary_accuracy: 0.4777 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6931 - binary_accuracy: 0.5118 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6932 - binary_accuracy: 0.4995 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6932 - binary_accuracy: 0.5073 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6934 - binary_accuracy: 0.4986 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6934 - binary_accuracy: 0.4864 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6933 - binary_accuracy: 0.4914 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6933 - binary_accuracy: 0.4950 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6931 - binary_accuracy: 0.4932 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6932 - binary_accuracy: 0.4923 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6934 - binary_accuracy: 0.4941 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/40\n",
      "2200/2200 [==============================] - 4s - loss: 0.6933 - binary_accuracy: 0.4864 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12105cba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB.fit(X_train_float, \n",
    "           Y_train, \n",
    "           batch_size=batch_size, \n",
    "           epochs=40, \n",
    "           verbose=1, \n",
    "           validation_data=(X_test_float, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Model B (120 epochs):\n",
      "Test accuracy: 49.100000%\n"
     ]
    }
   ],
   "source": [
    "# lower-case y_test is not encoded, CAPITAL Y_test is hot-encoded\n",
    "# use CAPITAL-Y_test!!\n",
    "score = modelB.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Model B (120 epochs):\")\n",
    "print('Test accuracy: {0:%}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So our accuracy was 48.6% (bad) and our validation accuracy was 50% (stinks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
