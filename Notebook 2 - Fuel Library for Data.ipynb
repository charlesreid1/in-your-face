{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuel Library for Data\n",
    "\n",
    "Notebook #1 explored the data that we were dealing with. This notebook utilizes the [Fuel library](https://github.com/mila-udem/fuel), which wraps data for machine learning pipelines, and the [lfw_fuel library](https://github.com/dribnet/lfw_fuel), which extends the Fuel library to the LFW dataset.\n",
    "\n",
    "This enables us to load image data and convert it into X and Y training/testing vectors in one call, like this:\n",
    "\n",
    "```\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"funneled\")\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"deepfunneled\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import imresize \n",
    "\n",
    "from lfw_fuel import lfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 12\n",
    "feature_width = 32\n",
    "feature_height = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cropImage(im):\n",
    "    im2 = np.dstack(im).astype(np.uint8)\n",
    "    # return centered 128x128 from original 250x250 (40% of area)\n",
    "    newim = im2[61:189, 61:189]\n",
    "    sized1 = imresize(newim[:,:,0:3], (feature_width, feature_height), interp=\"bicubic\", mode=\"RGB\")\n",
    "    sized2 = imresize(newim[:,:,3:6], (feature_width, feature_height), interp=\"bicubic\", mode=\"RGB\")\n",
    "    return np.asarray([sized1[:,:,0], sized1[:,:,1], sized1[:,:,2], sized2[:,:,0], sized2[:,:,1], sized2[:,:,2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = lfw.load_data(\"deepfunneled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop features\n",
    "X_train = np.asarray(list(map(cropImage, X_train)))\n",
    "X_test = np.asarray(list(map(cropImage, X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 train samples, 6 channels, 32x32\n",
      "1000  test samples, 6 channels, 32x32\n"
     ]
    }
   ],
   "source": [
    "# print shape of data while model is building\n",
    "print(\"{1} train samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_train.shape[1] == 1 else \"s\", *X_train.shape))\n",
    "print(\"{1}  test samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_test.shape[1] == 1 else \"s\", *X_test.shape))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional architecture\n",
    "# ~conv, conv, pool, drop, flatten, dense, drop, dense~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), input_shape=(6,32,32), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3,3), input_shape=(6,32,32), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['binary_accuracy'], optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2200 samples, validate on 1000 samples\n",
      "Epoch 1/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6943 - binary_accuracy: 0.4859 - val_loss: 0.6929 - val_binary_accuracy: 0.4990\n",
      "Epoch 2/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6919 - binary_accuracy: 0.5041 - val_loss: 0.6928 - val_binary_accuracy: 0.5010\n",
      "Epoch 3/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6913 - binary_accuracy: 0.5195 - val_loss: 0.6931 - val_binary_accuracy: 0.4860\n",
      "Epoch 4/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6903 - binary_accuracy: 0.5218 - val_loss: 0.6930 - val_binary_accuracy: 0.4860\n",
      "Epoch 5/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6900 - binary_accuracy: 0.5236 - val_loss: 0.6932 - val_binary_accuracy: 0.4960\n",
      "Epoch 6/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6887 - binary_accuracy: 0.5223 - val_loss: 0.6934 - val_binary_accuracy: 0.4940\n",
      "Epoch 7/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6887 - binary_accuracy: 0.5259 - val_loss: 0.6936 - val_binary_accuracy: 0.4960\n",
      "Epoch 8/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6862 - binary_accuracy: 0.5368 - val_loss: 0.6936 - val_binary_accuracy: 0.4940\n",
      "Epoch 9/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6854 - binary_accuracy: 0.5286 - val_loss: 0.6935 - val_binary_accuracy: 0.4870\n",
      "Epoch 10/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6831 - binary_accuracy: 0.5523 - val_loss: 0.6940 - val_binary_accuracy: 0.4810\n",
      "Epoch 11/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6828 - binary_accuracy: 0.5418 - val_loss: 0.6939 - val_binary_accuracy: 0.4840\n",
      "Epoch 12/12\n",
      "2200/2200 [==============================] - 1s - loss: 0.6798 - binary_accuracy: 0.5541 - val_loss: 0.6944 - val_binary_accuracy: 0.4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126e93da0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.694366986752\n",
      "Test accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
